\documentclass[../main.tex]{subfiles}
\begin{document}
Certains exercices sont vraiment difficiles, et ce n'est qu'en y passant du temps que l'on progresse le plus au niveau du raisonnement et des réflexes. N'hésitez pas !
 
La solution à chaque exercice n'est pas unique. Il est donc possible souvent de trouver une solution qui diffère. Il peut être intéressant de se poser la question de la raison des différences entre deux solutions (optimalité, lisibilité, rigueur, etc\dots). Il n'est ni garanti que les programmes proposés soient optimaux, ni que les démonstrations proposées soient les plus élégantes.

Toute proposition de démonstration ou de code peut être envoyé au contact donné en préface dans l'optique d'amélioration des futures éditions.

\textbf{Note quant aux codes :} certains codes ne sont ni annotés ni commentés. Pour ne pas surcharger le document, on indique simplement le chemin dans le répertoire des solutions du fichier de code qui contient la correction.
\section{Première partie}
On pose pour la suite $\mathcal{B} = \{0, 1\}$ et $N\in\mathbb{N}^{*}$
\subsection{Opérations logiques sur les mots binaires}
\solution{La compréhension pour mieux comprendre} On peut établir un lien entre les opérations logiques élémentaires et les opérations élémentaires en théorie des ensembles (union, union disjointe, intersection, privation). En effet :
\begin{itemize}
	\item $A\cup{B} = \{e\ |\ e\in{A}\vee e\in{B}\}$, on a : $\mathbb{P}(e\in A\cup{B}) = \mathbb{P}(e\in A) + \mathbb{P}(e\in B) - \mathbb{P}(e\in (A\cap B))$
	\item $A\uplus{B} = \{e\ |\ e\in{A}\oplus e\in{B}\}$, on a : $\mathbb{P}(e\in A\uplus{B}) = \mathbb{P}(e\in A) + \mathbb{P}(e\in B) - 2\times\mathbb{P}(e\in (A\cap B))$
	\item $A\cap{B} = \{e\ |\ e\in{A}\wedge e\in{B}\}$, on a : $\mathbb{P}(e\in A\cap{B}) = \mathbb{P}(e\in A)\mathbb{P}(e\in B)$
	\item $\Omega\setminus{A} = \{e\ |\ \neg e\in{A}\}$, on a $\mathbb{P}(e\in{\Omega\setminus{A}}) = 1 - \mathbb{P}(e\in{A})$
\end{itemize}
Il semble donc intuitif de retrouver des expressions semblables :
\begin{itemize}
	\item $\vee\ :\ (a, b) \mapsto a + b - ab$
	\item $\oplus\ :\ (a, b) \mapsto |a + b - 2ab|$ ($= |a - b|$)
	\item $\wedge\ :\ (a, b) \mapsto a\times b$
	\item $\neg\ :\ a \mapsto 1 - a$
\end{itemize}
\solution{Universalité des fonctions logiques élémentaires}
On considère un opérateur logique $\ast$ $N$-aire de $\mathcal{B}^{N}$ dans $\mathcal{B}^{M}$ où $M\in{\mathbb{N}^{*}}$. Soit $e\in{\mathcal{B}^{N}}$. On note $\ast(e) = \ast_{M-1}(e)\ast_{M-2}(e)\dots\ast_{0}(e)$. On observe que $\ast$ est entièrement définie par les fonctions $\ast_{i}, i\in{\llbracket0, M-1\rrbracket}$ de $\mathcal{B}^{N}$ dans $\mathcal{B}$.

Montrons donc que toute fonction logique de $\mathcal{B}^{N}$ dans $\mathcal{B}$ peut s'écrire comme une combinaison des fonctions $\vee$, $\wedge$ et $\neg$.

On peut partitionner $\mathcal{B}^{N}$ en deux ensembles disjoints $T$ et $F$ tels que $\ast = \mathbbm{1}_{T}$. C'est-à-dire que $T = \{e\in\mathcal{B}^{N}\ |\ \ast(e) = 1\} = \{t_{1}, \dots, t_{Card(T)}\}$.

D'où, en posant que l'égalité de deux éléments vaut 1 et leur différence vaut 0\footnote{On explicite dans la suite l'expression de $e = t_{i}$.} :
\begin{equation}
	\ast(e) = 1 \Leftrightarrow \displaystyle\bigvee_{i = 1}^{Card(T)}(e = t_i)
\end{equation}
On note $e = e_{N-1}\dots e_{0}$ et pour tout $i\in{\llbracket 1, k\rrbracket}$, $t_{i} = t_{i, N-1}\dots t_{i, 0}$.

On remarque que pour avoir $e = t_{i}$, il faut que :
\begin{itemize}
	\item les 1 de $e$ soient les 1 de $t_{i}$
	\item les 0 de $e$ soient les 0 de $t_{i}$.
\end{itemize}
On note $K_{1}(t_{i}) = \{k\in\{\llbracket 0, N-1\rrbracket\ |\ t_{i, k} = 1\}$ et $K_{0}(t_{i}) = \{k\in\{\llbracket 0, N-1\rrbracket\ |\ t_{i, k} = 0\}$. \\
Alors :
$$
\begin{array}{lcl}
	e = t_i & \Leftrightarrow & \displaystyle\bigwedge_{k\in{K_{1}(t_i)}}(e_k = t_{i, k})\displaystyle\bigwedge_{k\in{K_{0}(t_i)}}(e_k = t_{i, k}) \\
 & \Leftrightarrow & \displaystyle\bigwedge_{k\in{K_{1}(t_i)}}(e_k = 1)\displaystyle\bigwedge_{k\in{K_{0}(t_i)}}(e_k = 0) \\
 & \Leftrightarrow & \displaystyle\bigwedge_{k\in{K_{1}(t_i)}}e_k\displaystyle\bigwedge_{k\in{K_{0}(t_i)}}\neg{e_k}
\end{array}
$$
Finalement, on arrive à la définition par compréhension de $\ast$ :
\begin{displaymath}
\begin{array}{lclcl}
\ast & : & \mathcal{B}^{N} & \rightarrow & \mathcal{B} \\
& & (e_{N-1}, \dots, e_{0}) & \mapsto & \displaystyle\bigvee_{i = 1}^{Card(T)}\left(\displaystyle\bigwedge_{k\in{K_{1}(t_i)}}e_k\displaystyle\bigwedge_{k\in{K_{1}(t_i)}}\neg{e_k}\right)
\end{array}
\end{displaymath}
Les informations de la fonction sont contenues dans $T$.

\textbf{Remarque : }$\mathcal{B}^{N}$ est en bijection avec $\llbracket 0, 2^{N}-1\rrbracket$. Les opérations $\vee$, $\wedge$ et $\neg$ permettent donc de définir n'importe quelle fonction sur $\llbracket 0, 2^{N}-1\rrbracket$ d'arité finie, donc par exemple l'addition, la multiplication, etc\dots\footnote{On utilise évidemment pas cette formule pour définir les opérateurs arithmétiques. Il s'agit seulement de la preuve que ces opérateurs logiques sont capables de telles définitions.}
\begin{minitelbasicbox}{À propos des formes normales}
Dans l'expression précédente, les $e_{k}$ sont appelées des variables propositionnels en logique propositionnelle (ou d'ordre 0). Elles n'ont que deux interprétations possibles, \textit{Vrai} ou \textit{Faux}, 1 ou 0. La proposition logique associée à l'expression de la fonction logique admet des valeurs de vérités qui sont les couples $V = (v_{N-1}, \dots, v_{0})$ appelés \textit{interprétations} tels que $\ast(V) = Vrai$.

On peut montrer qu'une proposition logique en logique propositionnelle peut s'écrire de manière équivalente sous deux formes :
\begin{itemize}
	\item la forme normale disjonctive qui est une disjonction de conjonctions de variables :
	$$\displaystyle\bigvee\left(\displaystyle\bigwedge x_{i}\right)$$
	\item la forme normale conjonctive qui est une conjonction de disjonctions de variables :
	$$\displaystyle\bigwedge\left(\displaystyle\bigvee x_{i}\right)$$
\end{itemize}
En électronique, ces deux formes sont nommés respectivement \textit{somme de produits} et \textit{produit de sommes} car $(\mathcal{B}, \vee, \wedge)$ est un semi-anneau. On en retrouve des conséquences dans l'\refexercise{La compréhension pour mieux comprendre}.
\end{minitelbasicbox}
\solution{Porte NAND}
La table de vérité de NAND est :
\begin{center}
\begin{tabular}{c|c|c}
$A$ & $B$ & $A\uparrow{B}$ \\
\hline
0 & 0 & 1 \\
0 & 1 & 1 \\
1 & 0 & 1 \\
1 & 1 & 0 \\
\end{tabular}
\end{center}
On a ensuite pour tout $a, b\in{\mathcal{B}}$ :
\begin{itemize}
	\item $\neg(a) = a\uparrow{a}$
	\item $a\wedge b = \neg{a\uparrow{b}} = (a\uparrow{b})\uparrow(a\uparrow{b})$
	\item $a\vee b = \neg{(\neg a \wedge \neg{b})} = \neg{a}\uparrow\neg{b} = (a\uparrow a) \uparrow (b\uparrow b)$
\end{itemize}
\solution{Porte NOR}
La table de vérité de NOR est :
\begin{center}
\begin{tabular}{c|c|c}
$A$ & $B$ & $A\uparrow{B}$ \\
\hline
0 & 0 & 1 \\
0 & 1 & 0 \\
1 & 0 & 0 \\
1 & 1 & 0 \\
\end{tabular}
\end{center}
On a ensuite pour tout $a, b\in{\mathcal{B}}$ :
\begin{itemize}
	\item $\neg a = a\downarrow a$
	\item $a \vee b = \neg{(a \downarrow b)} = (a\downarrow b) \downarrow (a\downarrow b)$
	\item $a\wedge b = (\neg a)\downarrow (\neg b) = (a\downarrow a) \downarrow (b\downarrow b)$
\end{itemize}
\solution{Petit retour à l'algèbre fondamentale} Comme $\oplus$ est une opération \textit{bit à bit}, il suffit de vérifier que $G = (\mathcal{B}, \oplus)$ est un groupe commutatif.
\begin{itemize}
	\item $\oplus$ est une fonction de $\mathcal{B}^{2}$ dans $\mathcal{B}$ il s'agit bien d'une loi de composition interne.
	\item On observe que $0\oplus0 = x$ et $0\oplus 1 = 1$ et $1\oplus 0 = 1$. Donc $0$ est un élément neutre par $\oplus$. Comme $1\oplus1 = 0$, 0 est le seul élément neutre.
	\item $\oplus$ est associative
	\item Pour tout $x\in{\mathcal{B}}$, $x\oplus x = 0$ donc $x^{-1} = x$
	\item $\oplus$ est commutative
\end{itemize}
Donc $G$ est bien un groupe commutatif.

\solution{Inversibilité des décalages} Les décalages ne sont pas inversibles. En effet, quand des bits sont supprimés par un décalage de trop de bits, l'information est perdue. Un décalage dans l'autre sens ne produit que des 0. Par exemple : $(01000 \ll 2) \gg 2 = 00000 \neq 01000$
\subsection{Opérations arithmétiques}
\solution{Du décimal au binaire} 

\begin{minipage}{0.5\textwidth}
\begin{itemize}
	\item $(01001100)_{2}$
	\item $(10111100)_{2}$
	\item $(00100001)_{2}$
	\item $(01101101)_{2}$
	\item $(01011100)_{2}$
\end{itemize}
\end{minipage}
\begin{minipage}{0.5\textwidth}
\begin{itemize}
	\item $(11010011)_{2}$
	\item $(00000100)_{2}$
	\item $(11101110)_{2}$
	\item $(10100001)_{2}$
	\item $(01111110)_{2}$
\end{itemize}
\end{minipage}

\solution{P'tites démos}

Proposition 1 : $(btoi_{s}(v)) \equiv \displaystyle\sum_{i = 0}^{N-2}(b_{i}2^{i}) - b_{N-1}2^{N-1} + b_{N-1}2^{N} [2^{N}]$ \newline
Donc $\dot{(btoi_{s}(v))} = \dot{(btoi_{u}(v))}$, or la représentation en base 2 d'un entier naturel est unique, donc $v = w$.

Proposition 2 : $\displaystyle\sum_{i = 0}^{N-2}(b_{i}2^{i})$ est majoré par $\displaystyle\sum_{i = 0}^{N-2}(2^{i}) = 2^{N-1} - 1 < b_{N-1}2^{N-1}$

Proposition 3 : \[
\begin{array}{lcl}
-(btoi_{s}(\neg{v}) + 1) & = & -(\displaystyle\sum_{i = 0}^{N-2}((1-b_{i})2^{i}) - (1-b_{N-1})2^{N-1} + 1) \\
& = & \displaystyle\sum_{i = 0}^{N-2}((b_{i}2^{i}) - \displaystyle\sum_{i = 0}^{N-2}(2^{i}) + (1 - b_{N-1})2^{N-1} - 1 \\
& = & \displaystyle\sum_{i = 0}^{N-1}((b_{i}2^{i}) - 2^{N-1} - b_{N-1}2^{N-1} \\
& = & btoi_{s}(v)
\end{array}
\]

Proposition 4 :
\[
\begin{array}{lcl}
\dot{btoi_{u}(btoi^{-1}(x) + btoi^{-1}(y))} & = & \dot{btoi_{u}(btoi^{-1}(btoi_{u}(btoi^{-1}(x))) + btoi_{u}(btoi^{-1}(y)))} \\
 & = & \dot{(btoi_{u}(btoi^{-1}(x)) + btoi_{u}(btoi^{-1}(y)))} \\
 & = & \dot{(btoi_{u}(btoi^{-1}(x)))} + \dot{(btoi_{u}(btoi^{-1}(y)))} \\
 & = & \dot{x} + \dot{y} \\
 & = & \dot{(x + y)}
\end{array}
\]

Proposition 5 : Soit $v = v_{N-1}\dots v_{0}\in{\mathcal{B}^{N}}$.
\[
\begin{array}{lcll}
btoi_{u}(v\gg_{l}1)  & = & btoi_{u}(0v_{N-1}\dots v_{1}) \\
& = & \displaystyle\sum_{i = 1}^{N-1}(v_{i}2^{i-1}) + \underbrace{\left\lfloor\dfrac{v_{0}}{2}\right\rfloor}_{=0} \\
& = &  \left\lfloor\dfrac{btoi_{u}(v)}{2}\right\rfloor & \text{ car $\forall{(n, x)}\in{\mathbb{N}\times{\mathbb{R}}}, n + \lfloor{x}\rfloor = \lfloor{n + x}\rfloor$}
\end{array}
\]

Proposition 6 : Soit $v = v_{N-1}\dots v_{0}\in{\mathcal{B}^{N}}$.
\[
\begin{array}{lcl}
btoi_{s}(v\gg_{a}1)  & = & btoi_{s}(v_{N-1}v_{N-1}\dots v_{1}) \\
& = & \displaystyle\sum_{i = 1}^{N-1}(v_{i}2^{i-1}) - v_{N-1}2^{N-1} + \underbrace{\left\lfloor\dfrac{v_{0}}{2}\right\rfloor}_{=0} \\
& = &  \left\lfloor{\displaystyle\sum_{i = 0}^{N-1}(v_{i}2^{i-1}) - v_{N-1}2^{N-1}}\right\rfloor \\
& = &  \left\lfloor{\displaystyle\sum_{i = 0}^{N-2}(v_{i}2^{i-1}) - v_{N-1}2^{N-2}}\right\rfloor \\
& = & \left\lfloor\dfrac{btoi_{s}(v)}{2}\right\rfloor
\end{array}
\]

\subsection{Opérations sur les nombres à virgules}
\solution{Écriture en base 2 de nombres non entiers}
\begin{itemize}
	\item $(1110.1001)_2$
	\item $(1.01101)_2$
	\item $(111.0111)_2$
	\item $(0.0001001\underline{001}\dots)_2$ : il existe un nombre infini de décimales. On a le même phénomène avec la représentation de $\frac{1}{3}$ en décimal.
\end{itemize}
\solution{Racine carrée inverse rapide (1)} \\
On note $P = x^2 + y^2 + z^2$. Pour simplifier les notations, on note pour $x\in\mathbb{R}$ :
\begin{itemize}
	\item $itof(x) = btof(btoi^{-1}(x))$
	\item $ftoi(x) = btoi_s(ftob(x))$
\end{itemize}
On utilise ici trois résultats :
\begin{flalign}
    &log_2\left(\dfrac{1}{\sqrt{P}}\right) = -\frac{1}{2}log_2(P)\label{eq:log2}\\
    &\forall x\in\mathbb{R}_{f32},\ x = itof\left(A^{-1}(log_2(x) - B)\right)\label{eq:x_itof}\\
    &\forall x\in\mathbb{R}_{f32},\ log_2(x) = Aftoi(x) + B\label{eq:x_ftoi}
\end{flalign}
En utilisant l'égalité \eqref{eq:log2} dans \eqref{eq:x_itof} en $x = \frac{1}{\sqrt{P}}$, on obtient :
$$\frac{1}{\sqrt{P}} = itof\left(-\frac{1}{2A}(log_2(P) + 2B)\right)$$
En injectant \eqref{eq:x_ftoi}, on a alors :
$$\frac{1}{\sqrt{P}} = itof\left(-\frac{1}{2}ftoi(P) - \frac{3B}{2A}\right)$$
\subsection{Représentation hexadécimale}
\solution{Conversion binaire-hexadécimale}
\begin{itemize}
	\item $713705 = (1010\ 1110\ 0011\ 1110\ 1001)_{2} = 0\textsf{xAE}3\textsf{E}9$
	\item $8.8 = (1.00011001001001001001001)_{2}\times 2^{3} = 0100\ 0001\ 1000\ 1100\ 1001\ 0010\ 0100\ 1001 = 0\textsf{x}418\textsf{C}9249$
	\item $42 = (0001\ 1010)_{2} = 0\textsf{x}1\textsf{A}$
	\item $-1.1 = -(1.00010010010010010010010)_2\times{2^1} = 1100\ 0000\ 0000\ 1001\ 0010\ 0100\ 1001\ 0010 = 0\textsf{xC}0092492$
	\item $101 = (0110\ 0101)_2 = 0\textsf{x}65$
\end{itemize}
\subsection{Caractères ASCII}
\solution{Traduction ASCII 1} La chaîne de caractères décrite est : 
\begin{center}
``Minitel = GOAT''
\end{center}
\solution{Traduction ASCII 2} Le mot binaire qui décrit cette chaîne est :
$$\textsf{0x4F6820210A5175692065732D74752021083F}$$
\section{Deuxième partie}
\subsection{Bases du langage}
\subsubsection{Variables}
\solution{Interversion de variables par effet de bord}

\textbf{Code :} voir \detokenize{solutions/part2/chapter2/inter_var_side_effect.c}
\subsubsection{Formatage de chaînes de caractères}
\solution{Taille des types}

\textbf{Code :} voir \detokenize{solutions/part2/chapter2/taille_types.c}
\subsubsection{Opérateurs sur les variables}
\solution{Valeur}
 
Le premier code est strictement équivalent au code suivant :
\begin{minted}{c}
int i = 10;
i = i - i;
i--;
\end{minted}
D'où $i = -1$ en fin d'exécution. 
Le second code est strictement équivalent au code suivant :
\begin{minted}{c}
int i = 10;
i--;
i = i - i;
\end{minted}
D'où $i = 0$ en fin d'exécution.
 
\solution{Calcul d'expressions}
\begin{itemize}
	\item $a = 55$
	\item $b = 41$
	\item $c = 93$ (on évalue d'abord la division)
	\item $d = 65522$ ($93 - 107 = 0 - 14 \equiv 65535 - 13 [65536]$)
\end{itemize}
\solution{Priorité des opérateurs}
\begin{minted}{c}
int a = 6, b = 12, c = 24;
a = 25*12 + b;
printf("%d", a > 4 && b == 18);
(a >= 6&&b < 18) || c != 18;
c = a = b + 10;
\end{minted}
\solution{Interversion sans effet de bord (1)}
\inputminted{c}{solutions/part2/chapter2/inter_no_side_effect_1.c}
On note $a_{p}$ et $b_{p}$ les valeurs de $a$ et $b$ précédent l'interversion, et $a_{s}$ et $b_{s}$ les valeurs de $a$ et $b$ succédant à l'interversion.  
Les opérateurs $+$ et $-$ conservent l'écriture binaire des mots. L'échange est donc correct quelques soient les signatures de $a$ et $b$. 
Avec $a$ sur $N_{a}$ bits et $b$ sur $N_{b}$ bits avec $N_{a} > N_{b}$, on peut choisir $a = 2^{N_{b}}$ et $b$ quelconque. Alors $a + b = 2^{N_{b}}+b$ puis $b_{s} = 2^{N_{b}}+b_{p} - b_{p} = 2^{N_{b}} = -1 \neq{a}$. La permutation est donc incorrecte.
 
Cela peut être justifié sans calcul par l'observation suivante : les bits $a_{N_{a}-1}\dots a_{N_b}$ sont perdus par la modulation par $2^{N_{b}}$. La permutation ne peut donc être correcte.
 
\solution{Interversion sans effet de bord (2)}
\inputminted{c}{solutions/part2/chapter2/inter_no_side_effect_2.c}
En effet, on rappelle que pour tout ${x\in{\mathcal{B}^{N}}}$, $x\oplus{x} = 0$ et $x\oplus{0} = x$. Ainsi, $b_{s} = a\oplus{b}\oplus{b} = a$ et $a_{s} = a\oplus{b}\oplus{a} = b$.
 
\solution{Multiplication par décalage} On observe que $14 = (1110)_{2} = 2^{3} + 2^{2} + 2^{1} = (1 \ll 3) + (1 \ll 2) + (1 \ll 1)$. Il est toutefois possible de faire mieux en prêtant plus attention à la représentation binaire de 14. En effet, $14 + 1 = (1111)_{2} = 16 - 1$, c'est-à-dire $14 = 16 - 2 = 2^{4} - 2^{1} = (1 \ll 4) - (1 \ll 1)$
\inputminted{c}{solutions/part2/chapter2/mult_decalage.c}
Il est ainsi possible, parfois, d'optimiser l'opération de multiplication grâce à cette technique. La méthode classique de la multiplication est en effet plus lente à calculer, bien que plus générale. Cela est particulièrement visible lors de la multiplication de grands nombres :
$$987654321\times{65534} = (987654321 \ll 16) - (987654321 \ll 1)$$
Seules 2 décalages et une soustraction sont effectuées ($65534 = 65536 - 2 = 2^{16} - 2^{1}$)
 
\solution{Valeur absolue (1)}On utilise la particularité qu'un décalage logique (effectué sur \textsf{unsigned int}) n'effectue pas d'extension du signe :
\inputminted{c}{solutions/part2/chapter2/valeur_absolue.c}
Par ailleurs, $-1 = 0\textsf{xFFFFFFFF}$, donc \textsf{-1 \& x == x} est toujours vrai et \textsf{0 \& x == 0} est toujours vrai.
\subsubsection{Projection de type}
\solution{Quelques évaluations entières}
\begin{enumerate}
	\item \textit{vraie} car $0\textsf{xFFFFFFFF} + 1 = 0$ ($e1$ est sur 32 bits)
	\item \textit{faux} car $\textsf{(unsigned char)(-1)} = 255 = 0\textsf{xFF}$, d'où l'expression est égale à 0.
	\item \textit{vraie} car on a \textsf{!(e1 == e2)} $\equiv$ \textsf{e1 != e2} qui est vraie.
	\item \textit{vraie} car $64\wedge{e3} = 65 \equiv 1[8]$. D'où $\textsf{!(((64 $\wedge$ e3) \% 8) - 1)} = 1$.\newline Alors : $e4 \equiv{\textsf{(unsigned char)(257) - 2}} = -1$
\end{enumerate}
\subsubsection{Structures de contrôle du flot d'exécution}
\solution{}
\inputminted{c}{solutions/part2/chapter2/cours_structure_controle.c}
À partir de $u_{4}$ inclut, les valeurs de la suite sont fausses. On observe ainsi que $u_{3} = 808602$, d'où $u_{4} = 3\times808602^{2} - 5\times{808602} + 2 = 1961507540204 > 2^{31} - 1 = 2147483647$. Il y a un dépassement de capacité car la variable $u$ est stocké sur trop peu de bits. Le résultat est donc correct modulo $2^{32}$
 
\solution{Question d'âge}

\textbf{Code :} voir \detokenize{solutions/part2/chapter2/question_d_age.c}

\solution{Suite de Fibonacci}

\textbf{Code :} voir \detokenize{solutions/part2/chapter2/suite_fibonacci_1.c}

\solution{Test de primalité}\newline
Par définition, un nombre $n$ est premier si il possède exactement deux diviseurs distincts : $n$ et $1$. On peut donc tester la primalité d'un nombre en vérifiant qu'il ne possède pas d'autres diviseurs positifs strictement supérieurs à 1 que lui-même. Un premier algorithme naïf\footnote{Enfin, pas tout à fait puisqu'en ignorant les nombres pairs, on obtient seulement $\dfrac{N}{2}$ tours. Mais cela est équivalent asymptotiquement (les constantes restant des constantes).} est donc le suivant :
\inputminted{c}{solutions/part2/chapter2/primal_test.c}
Considérons maintenant un diviseur $d$ de $n$. Il existe donc $q$ tel que $n = dq$. On observe que si $d \geq \sqrt{n}$ alors $q \leq{\sqrt{n}}$. Par ailleurs, $q$ est un diviseur de $n$ lui aussi. Supposons que l'on ait vérifié que pour tout $1 < m \leq \sqrt{n}$, $m\nmid{n}$, alors il est absurde qu'il existe un diviseur de $n$ supérieur strictement à $\sqrt{n}$ car il existerait alors un diviseur $d$ strictement inférieur à $\sqrt{n}$.
 
Il suffit donc de vérifier la divisibilité de $n$ par les entiers impairs $m\leq{\sqrt{n}}$ :
\begin{minted}[firstnumber=10]{c}
for (int i = 3; i*i <= N && is_primal; i += 2) {
	is_primal = (N % i == 0) ? 0 : is_primal;
}
\end{minted}
On a $\dfrac{n}{\sqrt{n}}\underset{n\rightarrow{\infty}}{\rightarrow}\infty$, l'algorithme est donc plus efficace (il ne s'agit pas d'une constante).
\subsubsection{Routines}
\solution{Encore Fibonacci}

\textbf{Code :} voir \detokenize{solutions/part2/chapter2/suite_fibonacci_2.c}

\solution{Puissances entières}
\inputminted{c}{solutions/part2/chapter2/int_pow.c}
On observe que $(2^{31}-1)^{2^{32}-1}\approx{2^{31\times{2^{32}}}}$ est très largement supérieur à $2^{63} - 1$ qui est la valeur maximale d'un \textsf{long int}. En fait, pour stocker le résultat maximal de la fonction \textsf{pow}, il faudrait un disque dur d'environ $4\times{31} = 124\ Go$. Par ailleurs, la fonction \textsf{pow} reste infiniment loin d'être surjective dans $\mathbb{Z}$.
\subsubsection{Pointeurs}
\solution{Quelques procédures inutiles pour devenir un bot efficace}

\textbf{Code :} \detokenize{solutions/part2/chapter2/become_bot.c}

\solution{Interversion sans effet de bord (3)}
\inputminted{c}{solutions/part2/chapter2/inter_no_side_effect_3.c}
En effet, si $x = y$, à la première ligne, on a $*x = *x ^ *x = 0$, et $*y = *x = 0$. Les autres lignes sont inutiles, mais chacune a le même effet que la première.

\solution{Distance de Manhattan}
Le type \textsf{double} est sur $8 = 2\times{4}$ octets. Il permet donc de stocker deux nombres de type \textsf{float}.

Si $x$ est une variable de type \textsf{double}, $\&x$ est aussi l'adresse des premiers 4 octets, et $\&x + 4$ est \textit{mathématiquement} l'adresse des seconds 4 octets. Il faut toutefois faire attention. En C, $\&x$ est de type \textsf{double}. Si on veut lui ajouter 4, il faut le projeter en un pointeur de type sur 4 octets, et ajouter 1 à ce pointeur :
\begin{minted}{c}
double x; // 8 octets
float *x_left = (float*)&x; // pointeur sur 4 octets de gauche
float *x_right = (float*)&x + 1; // pointeur sur 4 octets de droite
\end{minted}
\textbf{Code complet :} voir \detokenize{solutions/part2/chapter2/manhattan_dist.c}

\solution{Valeur absolue (2)}
On veut simplement modifier le bit de signe. Toutefois, les opérations bit-à-bits sont interdites sur les nombres à virgules.

Les projections classiques \textsf{float x = (float)n;} et \textsf{int n = (int)x;} modifient la représentation binaire, ce qui n'est pas souhaité. On utilise à la place une idée semblable à celle utilisée pour l'\refexercise{Distance de Manhattan} :
\begin{minted}{c}
float abs(float x) {
	int int_x = *((int*)&x); // réinterprétation entière
	int_x &= 0x7FFFFFFF;	
	float abs_x = *((float*)&int_x); // réinterprétation flottante
	return abs_x;
}
\end{minted}
\solution{Racine carrée inverse rapide (2)}
La première étape est de déterminer la projection de type à effectuer pour calculer les fonctions :
\begin{itemize}
	\item $itof(x) = btof(btoi^{-1}(x))$
	\item $ftoi(x) = btoi_s(ftob(x))$
\end{itemize}
On utilise la même technique que pour l'\refexercise{Valeur absolue (2)} :
\begin{minted}{c}
float fast_inverse_square_root(float x) {
	int n = *((int*)&x);
	// transformation
	float y = *((float*)&n);
	return y;
}
\end{minted}
On a $A = \textsf{0x340003ce}$ et $B = \textsf{0xc2fe000f}$ interprétés comme des nombres flottants, d'où $-\frac{3B}{2A} = \textsf{0x4ebe7a62}$ selon la norme \textit{IEEE 754}. La difficulté est donc de trouver le mot binaire correspondant à la projection entière de $-\frac{3B}{2A}$ :
\begin{minted}{c}
int binary = 0x4ebe7a62;
float float_interpretation = *(float*)&binary;
int projection = (int)(float_interpretation);
printf("%x\n", projection);
\end{minted}
donne le mot binaire \textsf{0x5f3d3100}. Finalement :
\begin{minted}{c}
float fast_inverse_square_root(float x) {
	int n = *((int*)&x);
	n = 0x5f3d3100 - (n >> 1);
	float y = *((float*)&n);
	return y;
}
\end{minted}
On obtient $\frac{1}{\sqrt{0.01}} = 10 \approx 10.70$. L'erreur est assez élevé. En effet, la projection entière de \textsf{0x4ebe7a62} comporte une imprécision supplémentaire qui s'ajoute à celle de $log_2$.

On peut améliorer la précision en balayant les projections entières adjacentes. Avec \textsf{0x5f31eb85}\footnote{Le jeu \textit{Quake III utilise la constante \textsf{0x5f3759df}, mais utilise la méthode Newton. La constante doit aussi s'adapter à ça pour de meilleurs résultats.}}, on obtient une erreur de moins de $0.1\%$. Cette précision peut encore être améliorée en utilisant la \href{https://fr.wikipedia.org/wiki/M%C3%A9thode_de_Newton}{méthode de Newton}. 
\subsubsection{Interagir avec les flux standards}
\solution{Distance Euclidienne}

\textbf{Code :} \detokenize{solutions/part2/chapter2/euclidian_dist.c}

\solution{Somme d'entiers}

\textbf{Code :} \detokenize{solutions/part2/chapter2/int_sum.c}

\solution{Jeu du plus ou moins}

\textbf{Code :} \detokenize{solutions/part2/chapter2/plus_ou_moins.c}

La stratégie optimale est identique à celle de l'\refexercise{Recherche dichotomique} pour les mêmes raisons. Il faudra au maximum $\lceil log_2(N)\rceil$ tentatives pour trouver le nombre mystère.
\subsubsection{Tableaux statiques}
\solution{Les routines, direction la seconde classe !} Une fonction ne peut pas être construite pendant l'exécution du programme en C\footnote{Enfin, en assembleur on peut, mais là n'est pas le sujet, ce n'est plus du C.}.

\solution{Routines classiques de manipulation de tableaux}

\textbf{Code :} \detokenize{solutions/part2/chapter2/tab_select_sort.c}

On pose pour $i\in\llbracket 0; l(T)\rrbracket$ l'hypothèse de récurrence $P(i)$ : \textit{\og après le $i^e$ tour de boucle, on a les invariants suivants :
\begin{itemize}
	\item $T[0:i]$ est trié dans l'ordre croissant
	\item $T[0:i]$ contient les $i$ plus petits éléments de $T$.
\end{itemize}
\fg}

\underline{Initialisation} : le tableau $T[0:0]$ est vide. Les deux propositions constitutives de $P(0)$ sont immédiates car le tableau est vide.

\underline{Hérédité} : Soit $i\in\llbracket 0; l(T) - 1\rrbracket$. Supposons $P(i)$. Au $(i + 1)^e$ tour de boucle, on a $i_{min}$ l'indice de l'élément minimal dans $T[i:l(A)]$. Par HR, tous les éléments de $T[0:i]$ sont inférieurs à ceux de $T[i:l(A)]$ et donc à $T[i + i_{min}]$. Après le $(i+1)^e$ tour de boucle, on a échangé $T[i]$ et $T[i + i_{min}]$ donc $T[0:i+1]$ contient des éléments tous inférieurs à ceux de $T[i+1:l(A)]$ et $T[i]$ majore $T[0:i+1]$ qui est donc trié par ordre croissant. \newline
Donc les deux propositions de $P(i+1)$ sont vraies.

\underline{Conclusion} : L'hypothèse de récurrence est initialisée et héréditaire. Donc par principe de raisonnement par récurrence, pour tout $i\in\llbracket 0; l(T)\rrbracket$, $P(i)$ est vraie.

En particulier, pour $i = l(T)$, d'après le premier invariant, le tableau $T[0:l(T)] = T$ est trié à la fin de l'exécution de l'algorithme.

\solution{Recherche dichotomique}

\textbf{Question 1 :} La démonstration est assez immédiate. Supposons que $x\in T$. Il existe donc $i_x\in \llbracket{0; l(T)-1}\rrbracket$ tel que $T[i_x] = x$. 
\begin{itemize}
	\item Supposons $x\leq T[i]$. Comme $T$ est trié par ordre croissant, $i_x \leq i$
	\item Supposons $x > T[i]$. Comme $T$ est trié par ordre croissant, $i_x > i$ 
\end{itemize}
\textbf{Question 2 :} À chaque tour de boucle, on pose $i_m = \left\lfloor \frac{l(T)}{2}\right\rfloor$, et alors :
\begin{itemize}
	\item si $l(T) = 0$, renvoyer \textit{Faux}
	\item si $l(T) = 1$ et $T[0] = x$, renvoyer \textit{Vrai}
	\item si $x\leq T[i_m]$, $T\leftarrow T[0; i_m]$ et boucler
	\item si $x > T[i_m]$, $T\leftarrow T[i_m:l(T)]$ et boucler
\end{itemize}
Grâce au choix de $i_m$ effectué, on divise par deux la taille du tableau. Après au maximum $\lceil log_2(l(T))\rceil$ étapes, on a $l(T) \leq 1$ et le programme termine.
\inputminted{c}{solutions/part2/chapter2/dichotomique.c}
\solution{Liste des nombres premiers}

Dans la suite, on note\footnote{Voir section \ref{sec:mesures_du_cout} pour plus de détails. Ces notations ne sont pas \textit{nécessaires} pour la démonstration. Elles allègent l'écriture, c'est tout.} :
\begin{itemize}
	\item $O(f) = \{g:\mathbb{N}\rightarrow\mathbb{R}\ |\ \exists c\in\mathbb{R}_+^{*}, g\leq cf\}$.\newline
	C'est l'ensemble des fonctions dominés linéairement par $f$
	\item $\Omega(f) = \{g:\mathbb{N}\rightarrow \mathbb{R}\ |\ \exists c\in\mathbb{R}_+^*, f\leq cg\}$.\newline
	C'est l'ensemble des fonctions qui dominent linéairement $f$.
	\item $\Theta(f) = O(f)\cap \Omega(f)$ est l'ensemble des fonctions linéairement équivalentes à $f$
\end{itemize}
On écrit $a(n)\approx b(n)$, ou $a(n)\in\Theta(b(n))$, de manière équivalente à la phrase $\exists C_1, C_2\in\mathbb{R_+^*}, \forall n\in\mathbb{R}, C_1b(n) \leq a(n) \leq C_2b(n)$. 

On utilise les résultats suivants découlant du théorème des nombres premiers :
\begin{itemize}
	\item $\pi(i)\approx \dfrac{i}{ln(i)}$
	\item $p_i\approx i.ln(i)$, où $p_i$ désigne le $i^e$ nombre premier
\end{itemize}
\textbf{Questions 1 et 2 :}

La structure du code est la même dans les deux cas :
\begin{minted}{c}
#include <stdio.h>
#include <stdlib.h>

#define N ...

char primal_test(unsigned int n, unsigned int primes[], unsigned int counter);

int main() {
	unsigned int primes[N];
	unsigned int i = 3;
	unsigned int counter = 0;
	primes[0] = 2;
	while (i <= N) {
		if (primal_test(i, primes, counter)) {
			primes[++counter] = i;
			printf("%u;", primes[counter]);
		}
		i += 2;
	}
	unsigned nb_primes = counter + 1; // + 1 car 2 est aussi premier
	return EXIT_SUCCESS;
}
\end{minted}
Si on note pour $3\leq i\leq N$, $c_{test}(i)$ le nombre de tour de boucle effectué par $primal\_test(i)$, le cout total $C(N)$ est de :
$$C(N) = \displaystyle\sum_{i=3}^{N}c_{test}(i)$$

Les paramètres $primes$ et $counter$ sont inutiles pour la première question :
\begin{minted}{c}
char primal_test(unsigned int n, unsigned int primes[], unsigned int counter) {
	char is_primal = n == 2 || (n > 2 && n % 2 != 0); // nécessaire
	for (int i = 3; i*i <= n && is_primal; i += 2) {
		is_primal = (n % i == 0) ? 0 : is_primal;
	}
	return is_primal;
}
\end{minted}
On  a $c_{test}(i) = 0.5\sqrt{i} - 3$, d'où $C(N) = O(N^{\frac{3}{2}})$.

Pour la seconde :
\begin{minted}{c}
char primal_test(unsigned int n, unsigned int primes[], unsigned int counter) {
	char is_primal = 1; // premier par défaut
	for (unsigned int k = 0; k <= counter && is_primal && primes[k] * primes[k] <= n; k++) {
		is_primal = (n % primes[k] == 0 ? 0 : is_primal);
	}
	return is_primal;
}
\end{minted}
Si $n$ est premier, il faut tester tous les premiers inférieurs à $\sqrt{n}$. Le test fait donc au plus $\pi(\sqrt{n})$.

\textbf{Question 3 :}

L'algorithme décrit ne suit pas la même structure. Cette structure semble seulement plus complexe à écrire pour aboutir au même résultat. On montre à la dernière question que tel n'est pas le cas et que le crible d'Eratosthène est plus rapide que l'algorithme "naïf" précédent.
\inputminted{c}{solutions/part2/chapter2/eratosthene.c}
\textbf{Question 4 :}

\textbf{Analyse du crible d'Eratosthène :}

La boucle \textit{for} fait $\left\lceil\frac{N}{p_i}\right\rceil - p_i$ tours de boucle et la boucle \textit{do-while} en fait $p_{i+1} - p_i$ puisqu'elle part de $p_i$ pour s'arrêter au premier juste suivant, c'est-à-dire $p_{i+1}$.\newline
D'où :
$$C_{e}(N) = \displaystyle\sum_{i = 1}^{\pi(\sqrt{N})}\left\lceil\frac{N}{p_i}\right\rceil + p_{i+1} - 2p_i$$
Par ailleurs :
$$\begin{array}{lcll}
p_{i+1} - 2p_i & \approx & (i+1)ln(i+1) - 2iln(i) \\
 & = &i(ln(1 + \frac{1}{i})) + ln(i+1) - i.ln(i)\\
 &\leq & iln(2) + ln(i+1)-i.ln(i) \\
 &\leq &0 &\text{pour $i \geq 4$}
\end{array}$$ 
D'où :
$$\begin{array}{lcl}
C_{e}(N) & \approx & \displaystyle\sum_{i = 4}^{\pi(\sqrt{N})} \left\lceil\frac{N}{p_i}\right\rceil + p_{i+1} - 2p_i \\
&\leq & \displaystyle\sum_{i = 4}^{\pi(\sqrt{N})} \frac{N}{p_i}
\end{array}
$$
On conclut une comparaison série-intégrale :
$$\begin{array}{lcl}
C_{e}(N) & \approx & N\displaystyle\sum_{i=4}^{2\frac{\sqrt{N}}{ln(N)}}\frac{1}{i.ln(i)} \\
& \leq & N\displaystyle\int_3^{2\frac{\sqrt{N}}{ln(N)}}\frac{1}{x.ln(x)}\mathrm{d}x \\
& \approx & N.ln\left(\dfrac{2\sqrt{N}}{ln(N)}\right) \\
C_{e}(N) & \in & O(N.ln(ln(N)))
\end{array}
$$

\textbf{Analyse de l'algorithme par test de primalité :}

On cherche d'abord un majorant, pour se donner une idée du nombre d'opérations effectués par l'algorithme. On a environ $\dfrac{N}{p_i}$ multiples de $p_i$ inférieurs à $N$. Pour être certain de disqualifier chacun de ces multiples, il faut vérifier sa divisibilité par les $i$ premiers nombres premiers. Ainsi, les multiples de $p_1 = 2$ doivent être disqualifiés par une division par 2. Les multiples de $p_2 = 3$ doivent être disqualifiés par une division par 2 et une division par 3, etc\dots On compte clairement trop d'opérations, puisque certains multiples de $p_i$ sont aussi multiples de $p_j < p_i$ et nécessiterons moins de $i$ opérations pour être disqualifiés.

Cela donne :
$$\begin{array}{lcll}
C_{pt}(N) & \leq & \displaystyle\sum_{i = 1}^{\pi(\sqrt{N})}i\dfrac{N}{p_i} \\
& \approx & \dfrac{N}{2} + 2\dfrac{N}{3} + N\displaystyle\sum_{i = 3}^{2\frac{\sqrt{N}}{ln(N)}}\frac{1}{ln(i)} \\
& \leq & 7\dfrac{N}{6} + N\displaystyle\int_{2}^{2\frac{\sqrt{N}}{ln(N)}}\dfrac{1}{ln(x)}\mathrm{d}x & \text{comparaison série-intégrale}\\
& = & 7\dfrac{N}{6} + N\times Ei\left(ln\left(2\frac{\sqrt{N}}{ln(N)}\right)\right) & \text{Exponentielle intégrale en posant $u = ln(x)$} \\
\end{array}$$
On utilise le développement en série entière :
$$\begin{array}{lcl}Ei(x) & = & \gamma + ln|x| + \displaystyle\sum_{k = 1}^{+\infty}\frac{x^k}{k.k!} \\
& \leq & \gamma + ln|x| + e^x - 1
\end{array}$$
Alors :
$$\begin{array}{lcl}C_{pt}(N) & \leq & (\frac{1}{6} + \gamma)N + N\left[ln\left|ln\left(2\frac{\sqrt{N}}{ln(N)}\right)\right| + 2\frac{\sqrt{N}}{ln(N)}\right] \\
& \in & O\left(\frac{N\sqrt{N}}{ln(N)}\right)
\end{array}$$
On cherche ensuite un minorant en supposant que l'algorithme de la \textbf{Question 2} ne teste que les nombres premiers. Il s'agit d'une sous-estimation du nombre d'opérations effectués :
$$\begin{array}{lcll}
C_{pt}(N) & \geq & \displaystyle\sum_{i = 3}^{\pi(N)}\pi(\sqrt{p_i}) \\
 & \approx & \displaystyle\sum_{i = 3}^{\frac{N}{ln(N)}}\frac{\sqrt{i.ln(i)}}{ln(\sqrt{i.ln(i)})} \\
& \approx & 2\displaystyle\int_{3}^{\frac{N}{ln(N)}} \frac{\sqrt{i.ln(i)}}{ln(i.ln(i))}\mathrm{d}i& \text{ par comparaison série-intégrale}\\
\end{array}$$
On ne va pas s'amuser à essayer d'intégrer cette merde\footnote{Btw j'ai essayé\dots ça s'est pas bien passé\dots}.

Par contre, on peut utiliser le résulat de majoration. On a :
$$
\left(\frac{x\sqrt{x}}{ln(x)}\right)' = \frac{\sqrt{x}(\frac{3}{2}ln(x) - 1)}{ln^2(x)}
$$
On va donc comparer $A(x) = \frac{\sqrt{x.ln(x)}}{ln(x.ln(x))}$ et $B(x) = \frac{\sqrt{x}(\frac{3}{2}ln(x) - 1)}{ln^2(x)}$ :
$$\dfrac{A(x)}{B(x)} = \dfrac{ln^{2.5}(x)}{(ln(x) + ln(ln(x)))(\frac{3}{2}ln(x) - 1)}$$
On a $\frac{A(x)}{B(x)}\underset{x\rightarrow +\infty}{\rightarrow}+\infty$. En particulier, il existe $r\in\mathbb{R}_+^*$ tel que pour tout $x\geq r$, $A(x) \geq B(x)$. $A$ et $B$ sont positifs. Donc :
$$\begin{array}{lcl}
\displaystyle\int_r^{\frac{N}{ln(N)}}A(x)\mathrm{d}x & \geq & \displaystyle\int_r^{\frac{N}{ln(N)}}B(x)\mathrm{d}x \\
& = & \dfrac{\frac{N}{ln(N)}\sqrt{\frac{N}{ln(N)}}}{ln\left(\frac{N}{ln(N)}\right)} + C \\
& \in & \Omega\left(\dfrac{N\sqrt{N}}{ln^{1.5}(N)ln(\frac{N}{ln(N)})}\right)
\end{array}
$$
L'algorithme de la \textbf{Question 2} est donc asymptotiquement plus lent que le crible d'Eratosthène\footnote{Le résultat est moins précis que celui de M. O'Neill, professeur au département d'informatique de l'université de Harvey Mudd, qui trouve que l'algorithme de la \textbf{Question 2} est en $\Theta\left(\frac{N\sqrt{N}}{(ln(N))^2}\right)$.}
\subsubsection{Tableaux dynamiques}
\solution{Conversion en binaire}

\textbf{Code :} \detokenize{solutions/part2/chapter2/nat2bin.c}
\subsubsection{Tableaux multidimensionnels}
\solution{Afficher un tableau 2D}

\textbf{Code :} \detokenize{solutions/part2/chapter2/tab_display_2d.c}

\solution{Affichage du triangle}\newline
Version généralisée pour \textsf{N\_LINES} quelconque.

\textbf{Code :} \detokenize{solutions/part2/chapter2/triangle.c}

\solution{Matrices (1)} \newline
Soit $m$ une matrice implantée en C. Il faut d'abord déterminer ce que signifie $mat[i] \equiv ^*((char^*)m + i\times sizeof(double^*))$. Le $double^*$ est le type d'une ligne. Donc $l_{i} = mat[i]$ est le pointeur vers la $i^{e}$ ligne. On a alors $l_{i}[j]$ le $j^e$ élément de la $i^e$ ligne. En remplaçant $l_{i}$ par son expression, on a :
$$mat[i][j] \equiv\ ^*(^*(mat + i) + j) \equiv (^*((char^*)mat + i\times sizeof(double^*)) + j\times sizeof(double)) $$
\textbf{Code :} \detokenize{solutions/part2/chapter2/matrix.c}
\subsubsection{Structures}
\solution{Matrices (2)} \newline
Il suffit d'utiliser l'interface suivante, les modifications des routines sont assez triviales :
\inputminted{c}{solutions/part2/chapter2/matrix.h}
\solution{Optimisation d'alignement}
Avec un \textsf{double} à la place d'un \textsf{int} :
\begin{itemize}
	\item $\textsf{sizeof(struct ExampleUnaligned)} = 24$
	\item $\textsf{sizeof(struct ExampleAligned)} = 16$
\end{itemize}
\solution{Listes chaînées}

\textbf{Code :} \detokenize{solutions/part2/chapter2/linkedlist_1.c}
\subsubsection{Modulation et entêtes}
\solution{Un module de listes chaînées} \newline
On écrit le code des fonctions de l'exercice précédent dans un fichier \textit{``linkedlist.c''}\footnote{Dans le répertoire de travail du fichier \textit{``main.c''}} que l'on fait débuter par la ligne \textsf{\#include "linkedlist.h"}. On écrit ensuite dans le même répertoire de travail le fichier \textit{``linkedlist.h''} suivant, qui contient les prototypes et les structures :
\inputminted{c}{solutions/part2/chapter2/linkedlist_2.h}
Il conserve la même fonction \textsf{main} du fichier \textit{``main.c''} avec une inclusion du module :
\inputminted{c}{solutions/part2/chapter2/linkedlist_2.c}
Et compilation puis exécution :
\begin{minted}[frame=single]{bash}
user@computer ~/working_directory> gcc main.c linkedlist.c -o main
user@computer ~/working_directory> ./main
->4->5->6
user@computer ~/working_directory>
\end{minted}
\solution{Calculatrice}

\textbf{Code :} \detokenize{solutions/part2/chapter2/calculatrice.c}

\solution{AtoI}

\textbf{Code :} \detokenize{solutions/part2/chapter2/atoi.c}
\subsubsection{Interagir avec les flux de fichiers}
\subsection{Concepts avancés}
\subsubsection{Passage d'arguments au programme}
\solution{Liste des arguments}

\textbf{Code :} \detokenize{solutions/part2/chapter3/list_args.c}

\solution{Un cat minimaliste}

\textbf{Code :} \detokenize{solutions/part2/chapter3/cat.c}
\subsubsection{Pointeurs de routines}
\solution{Mapping}

\textbf{Code :} \detokenize{solutions/part2/chapter3/mapping.c}
\subsubsection{Directives du préprocesseur (2)}
\solution{Tout dépend du système}
\begin{minted}{c}
#include <stdio.h>
#include <stdlib.h>

int main() {
	#if defined(__linux__)
	printf("Chouette !\n");
	#elif defined(_WIN32)
	printf("Beeerk !\n");
	#endif
	return EXIT_SUCCESS;
}
\end{minted}
\solution{Libération sécurisée}
\begin{minted}[linenos=false]{c}
#define safe_free(p) do {free((void*)p);p = NULL;} while(0)
\end{minted}
\subsubsection{Routines variadiques}
\solution{À un doigt du zéro}

\textbf{Code :} \detokenize{solutions/part2/chapter3/un_doigt_du_zero.c}
\section{Troisième partie}
\subsection{Types abstraits}
\solution{Tableaux dynamiques}

On considère la signature de la fonction équivalente de la procédure de redimensionnement :
$$redimensionner(Tableau, Entier)\rightarrow Tableau$$
On étend la spécification par les équations suivantes, définies pour tout tableau $t$, et pour tous entiers $i$ et $n$ :
\begin{itemize}
	\item $taille(redimensionner(t, n)) = n$
	\item $taille(t)\leq i < n \Rightarrow init(redimensionner(t, n), i) = Faux$ (ok même si $n < taille(t)$)
	\item $0\leq i < min\left(n, taille(t)\right) \Rightarrow init(redimensionner(t, n), i) = init(t, i)$
	\item $0\leq i < min\left(n, taille(t)\right)\wedge init(redimensionner(t, n), i) = Vrai \Rightarrow lire(redimensionner(t, n), i) = lire(t, i)$
\end{itemize}
\textbf{Code :} \detokenize{solutions/part3/chapter2/tableaux_dynamiques}

\solution{Entiers relatifs et rationnels}

Malgré la formulation de la question, la difficulté n'est pas théorique mais technique. D'ailleurs, le code proposé pour l'implantation de $(\mathbb{Z}, +, \times)$ est \textit{très largement} optimisable.

Il est surtout fondamental de comprendre la différence entre le type abstrait algébrique $(\mathbb{Z}, +, \times)$, qui est implanté dans cet exercice, et les types abstraits $\frac{\mathbb{Z}}{2^N\mathbb{Z}}$ où $N$ est le nombre de bits maximal, qui sont les types donnés nativement par le langage C (\textsf{char}, \textsf{short int}, \textsf{int}, etc\dots).

Le type $(\mathbb{Z}, +, \times)$ est beaucoup plus lourd à implanter en termes de performances car il est plus difficile d'avoir une accélération matérielle (au niveau du processeur) pour le gérer. Par ailleurs, la plupart des cas d'utilisations n'en ont pas l'utilité, ce qui justifie l'obligation de l'implanter logiciellement.

\textbf{Code :} \detokenize{solutions/part3/chapter2/adt_entiers_et_rationnels}

\subsection{Listes}
\solution{Listes virtuelles}

\textbf{Code :} \detokenize{solutions/part3/chapter2/listes_virtuelles}

\solution{Listes par tableaux} C'est l'implantation des listes de Python.

\textbf{Code :} \detokenize{solutions/part3/chapter2/listes_tableaux}

\textbf{Coûts en tête et queue de liste :}

Les coûts d'accès et de suppression sont visiblement fonctions de $O(1)$. Pour l'insertion en tête ou en queue de liste, c'est le redimensionnement du tableau qui pose problème. On note $c(k)$ le coût de la $k^e$ insertion. Initialement, la liste est de longueur $0$ L'insertion de l'élément numéro $1 = 2^0$ amène à doubler sa taille. Par récurrence, on obtient que l'insertion $2^i$ dans la liste coûte $2^{i+1}$ opérations tandis que les autres insertions coûtent toutes $1$ opération à un facteur indépendant de $k$ près (qui ne change pas le résultat final puisque la domination linéaire ``écrase'' le facteur). Autrement dit :
$$c(k) \approx \left\{\begin{array}{ll}
k + 1 & \text{si } k = 2^i \\
1 & \text{sinon}
\end{array}\right.$$
\textbf{Remarque :} On approxime $2k\approx k + 1$ car les deux ne diffèrent qu'à une transformation linéaire indépendante de $k$ près.

On observe que $\sum_{k = 2^i}^{2^{i+1} - 1}c(k) = 2^{i+1} = \sum_{k = 2^i}^{2^{i+1} - 1}2$. Le coût est linéaire.

Soit $n\in\mathbb{N}$. On note $e = $ $n = \lfloor{log_2(n)}\rfloor$. On a $n = 2^e + r$, où $0\leq r < 2^e$. Le coût des $n$ premières insertions est finalement :
$$\begin{array}{lcl}
C(n) & = & \displaystyle\sum_{i = 0}^{e - 1}\sum_{k = 2^i}^{2^{i+1}-1}c(k) + r \\
 & = & \displaystyle\sum_{i = 0}^{e - 1}\sum_{k = 2^i}^{2^{i+1} - 1}2 + r \\
 & \in & O(2^e + r) \\
 & = & O(n)
 \end{array}$$
 Donc le coût amortie d'une seule insertion est fonction de $O(1)$.

 \textbf{Coûts en milieu de liste :}

 Contrairement à l'implantation par listes chaînées, l'accès à un élément quelconque est en $O(1)$ puisqu'il s'agit d'un tableau. L'insertion et la suppression sont en $O(n)$ \textit{dans tous les cas} puisqu'il faut décaler tous les éléments suivants du tableau. Pour une liste chaîné, l'accès à un élément quelconque dans le cas général est en $O(n)$. Par contre, pour l'insertion et la suppression, on observe que bien que le coût soit $O(n)$ en général, si on parcours la liste pour d'autres raisons, on peut supprimer des éléments \textit{au passage} en $O(1)$.

 \textbf{Conclusion des \refexercise{Listes virtuelles} et \refexercise{Listes par tableaux}}

 Le point le plus remarquable des codes C des deux exercices tient à l'identicité des fichiers \textit{main.c} et de l'implantation de \textit{list\_display}. Le fait d'implanter la signature de liste permet de ne se servir que d'elle et d'être absolument indépendant de l'implantation.

 Du point de vue des coûts asymptotiques, on observe que l'implantation par tableau permet des accès plus rapide et l'implantation par chaînage permet des modifications plus rapides.

 Du point de vue des constantes, le code des listes chaînés est plus complexe et demande certaines optimisations comme un noeud virtuel pour éviter trop de branchements conditionnels. Si on ne fait qu'ajouter en tête ou en queue de liste, l'implantation par tableau semble relativement correcte au défaut du surcoût de redimensionnement. Par contre, l'implantation par tableau évite trop d'allocations dynamiques et est optimal pour la quantité de mémoire utilisée \textit{par élément}. Si la taille de la liste est bornée et proche par le dessous d'une puissance de 2, l'implantation par tableau est relativement optimale.

\solution{Axiomes algébriques}

\textbf{Pile :} Toute pile est construite canoniquement sous la forme $P= empiler(\dots(empiler(pile\_vide(), e_1)\dots), e_n)$. Donc il faut décrire les opérations selon les formes canoniques résultant de $pile\_vide$ et $empiler$ (sachant que certaines opérations comme $depiler(pile\_vide())$ sont simplement impossibles).

Pour toute $Pile:P$ quelconque et tout $\textit{Élément}:e$ quelconque, on pose :
\begin{itemize}
	\item $est\_vide(pile\_vide()) = \textit{Vrai}$
	\item $est\_vide(empiler(P, e)) = \textit{Faux}$
	\item $sommet(empiler(P, e)) = e$
	\item $depiler(empiler(P, e)) = P$
\end{itemize}

\textbf{File :} Même remarque que pour les piles, la forme canonique d'une file est construite par compositions de $file\_vide$ et d'$enfiler$.

Pour toute $File:F$ quelconque et tout $\textit{Élément}:e$ quelconque, on pose :
\begin{itemize}
	\item $est\_vide(file\_vide()) = \textit{Vrai}$
	\item $est\_vide(enfiler(F, e)) = \textit{Faux}$
	\item $premier(enfiler(F, e)) = e$
	\item $dernier(enfiler(F, e)) = \left\{\begin{array}{ll}dernier(F) & \text{si $\neg est\_vide(F)$} \\ e & \text{sinon}\end{array}\right.$
	\item $defiler(enfiler(F, e)) = \left\{\begin{array}{ll}enfiler(defiler(F), e) & \text{si $\neg est\_vide(F)$} \\ file\_vide() & \text{sinon}\end{array}\right.$
\end{itemize}

\solution{Piles et files}

On ne décrit que la construction d'une file \textit{via} deux piles. La construction d'une pile \textit{via} deux files est duale. Les analyses de correction et de complexité sont identiques.

\textbf{Construction de la structure :}

On veut définir une file comme un couple de deux piles $P_e$ et $P_s$ (avec $e$ pour \underline{e}ntrée et $s$ pour \underline{s}ortie). On pose pour $F = (P_e, P_s)$ :
\begin{itemize}
	\item $file\_vide() = (pile\_vide(), pile\_vide())$
	\item $est\_vide(F) = est\_vide(P_e)\wedge est\_vide(P_s)$
	\item $premier(F) = sommet(P_e)$
	\item $enfiler((P_e, P_s), e) = (empiler(P_e, e), P_s)$
\end{itemize}
On définit alors une nouvelle opération spécifique à notre structure : $vider(P_e, P_s)$, qui va dépiler chaque élément de $P_e$ pour l'empiler sur $P_s$ :

\begin{algorithm}
\caption{Vider}\label{alg:vider_piles}
\KwIn{$\textit{Pile}:P_e$, $\textit{Pile}:P_s$}
\While {$\neg est\_vide(P_e)$} {
	$P_s \leftarrow empiler(P_s, sommet(P_e))$\;
	$P_e \leftarrow depiler(P_e)$\;
}
\Return $(P_e, P_s)$\;
\end{algorithm}

On utilise cette opération pour construire les opérations $defiler$ et $dernier$ de $F$ :

\begin{algorithm}
\caption{$dernier(F)$}\label{alg:dernier}
\KwIn{$\textit{File}:F = (P_e, P_s)$}
\If {$est\_vide(P_s)$} {
	$(P_e, P_s) \leftarrow vider(P_e, P_s)$ \tcp{On suppose évidemment que la file est non vide.}
}
\Return $sommet(P_s)$
\end{algorithm}
\begin{algorithm}
\caption{$defiler(F)$}\label{alg:defiler}
\KwIn{$\textit{File}:F = (P_e, P_s)$}
\eIf {$est\_vide(P_s)$} {
	$(P_e, P_s) \leftarrow vider(P_e, P_s)$ \tcp{\textit{idem}}
	$P_s \leftarrow depiler(P_s)$\;
} {
	$P_s \leftarrow depiler(P_s)$\;
}
\Return $(P_e, P_s)$
\end{algorithm}

\textbf{Correction :} il faut vérifier que les axiomes du type abstrait algébrique de \textit{File} sont bien respectés par cette structure.

Les trois premiers axiomes sont immédiatement vérifiés :
\begin{itemize}
	\item $est\_vide(file\_vide()) = est\_vide(pile\_vide()) \wedge est\_vide(pile\_vide()) = \textit{Vrai}$
	\item $est\_vide(enfiler(F, e)) = est\_vide(empiler(P_e, e)) \wedge est\_vide(P_s) = \textit{Faux}$
	\item $premier(enfiler(F, e)) = sommet(empiler(P_e, e)) = e$
\end{itemize}

\textbf{Complexité :}

\solution{Optimizing greater than abstraction}

\textbf{Code :} \detokenize{solutions/part3/chapter2/listes_xor}

\solution{Fusion triée de listes}

On utilise l'implantation des listes de l'\refexercise{Listes virtuelles}

\textbf{Code :} \detokenize{solutions/part3/chapter2/fusion_listes.c}

La complexité temporelle est immédiatement fonction de $O(n + m)$ (où $n$ et $m$ sont les longueurs des deux listes) puisqu'on effectue exactement $n + m$ tours de boucle et que chaque tour est de complexité temporelle fonction de $O(1)$

\end{document}